{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gq5V5YZmHzYK",
    "outputId": "8e027dbb-333f-46b3-8b56-d1c1e38e9961"
   },
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi\n",
    "\n",
    "# Install libs (headless OpenCV avoids GUI issues in Colab)\n",
    "!pip -q install \"ultralytics>=8.3.0\" opencv-python-headless onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3GxVS5chIIOZ",
    "outputId": "989d336d-0d97-4bc9-fcd2-4831f529f1d9"
   },
   "outputs": [],
   "source": [
    "# --- Fixed Cell 2: robust demo video + quick inference ---\n",
    "from ultralytics import YOLO\n",
    "import urllib.request, os, pathlib\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")   # already cached\n",
    "\n",
    "# Try a few known-good sample videos (small)\n",
    "urls = [\n",
    "    # OpenCV sample traffic clip\n",
    "    \"https://github.com/opencv/opencv/raw/master/samples/data/vtest.avi\",\n",
    "    # Another OpenCV sample\n",
    "    \"https://github.com/opencv/opencv_extra/raw/master/testdata/highgui/video/big_buck_bunny.avi\",\n",
    "]\n",
    "\n",
    "dest = \"demo.mp4\"  # we'll rename whatever we get to .mp4 for convenience\n",
    "ok = False\n",
    "for i, u in enumerate(urls):\n",
    "    tmp = f\"demo_src_{i}\" + pathlib.Path(u).suffix\n",
    "    try:\n",
    "        print(f\"Downloading: {u}\")\n",
    "        urllib.request.urlretrieve(u, tmp)\n",
    "        # normalize extension -> .mp4 (Ultralytics handles multiple formats, but keep one name)\n",
    "        os.rename(tmp, dest)\n",
    "        ok = True\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {e}\")\n",
    "\n",
    "if not ok:\n",
    "    raise RuntimeError(\"Could not fetch a sample video. As a fallback, upload a short dashcam/traffic clip and set dest='yourfile.mp4'.\")\n",
    "\n",
    "# Inference on video, save annotated frames to runs/detect/predict*/\n",
    "results = model.predict(source=dest, conf=0.25, save=True)\n",
    "\n",
    "# Show where results were saved\n",
    "print(\"Saved to:\", results[0].save_dir if results else \"No results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JeGHe8TIL1Q",
    "outputId": "18dba643-21bc-4369-b279-8d44b2cb986e"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Fast sanity fine-tune: 5â€“10 epochs on small sample\n",
    "model.train(data=\"coco128.yaml\", epochs=5, imgsz=640, batch=16, device=device)\n",
    "\n",
    "# Path to best weights\n",
    "best = model.ckpt_path if hasattr(model, \"ckpt_path\") else \"runs/detect/train/weights/best.pt\"\n",
    "print(\"Best weights:\", best)\n",
    "\n",
    "# Quick validation\n",
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77QrdcSeLOCv",
    "outputId": "fbc04667-9a5b-4ca6-8b90-bb69495a6132"
   },
   "outputs": [],
   "source": [
    "# --- Cell: find newest best.pt, export to ONNX, show paths ---\n",
    "import glob, os, time, pathlib\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Find the latest best.pt under runs/detect/*/weights/best.pt\n",
    "cands = glob.glob(\"runs/detect/*/weights/best.pt\")\n",
    "assert cands, \"No best.pt found. Did training finish? Check runs/detect/*/weights/\"\n",
    "best_pt = max(cands, key=os.path.getmtime)\n",
    "print(\"Using best weights:\", best_pt)\n",
    "\n",
    "# Export to ONNX next to the .pt\n",
    "m = YOLO(best_pt)\n",
    "onnx_path = m.export(format=\"onnx\", opset=12, dynamic=True)\n",
    "print(\"Exported ONNX:\", onnx_path)\n",
    "\n",
    "# If you want TorchScript too (optional):\n",
    "# ts_path = m.export(format=\"torchscript\")\n",
    "# print(\"Exported TorchScript:\", ts_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ZGiPxYowMoSq",
    "outputId": "dda1440c-5294-4280-eb72-9481c37afaa0"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"runs/detect/train/weights/best.pt\")\n",
    "files.download(\"runs/detect/train/weights/best.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
